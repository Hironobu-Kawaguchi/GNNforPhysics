{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8ee0b0",
   "metadata": {},
   "source": [
    "# Data check ç”¨ notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29c9d848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 11:58:18.287395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow will not use sklearn by default. This improves performance in some cases. To enable sklearn export the environment variable  TF_ALLOW_IOLIBS=1.\n",
      "WARNING:tensorflow:TensorFlow will not use Dask by default. This improves performance in some cases. To enable Dask export the environment variable  TF_ALLOW_IOLIBS=1.\n",
      "WARNING:tensorflow:TensorFlow will not use Pandas by default. This improves performance in some cases. To enable Pandas export the environment variable  TF_ALLOW_IOLIBS=1.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tree\n",
    "\n",
    "\n",
    "from learning_to_simulate import learned_simulator\n",
    "from learning_to_simulate import noise_utils\n",
    "from learning_to_simulate import reading_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a96b50ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "flags.DEFINE_enum(\n",
    "    'mode', 'train', ['train', 'eval', 'eval_rollout'],\n",
    "    help='Train model, one step evaluation or rollout evaluation.')\n",
    "flags.DEFINE_enum('eval_split', 'test', ['train', 'valid', 'test'],\n",
    "                  help='Split to use when running evaluation.')\n",
    "flags.DEFINE_string('data_path', None, help='The dataset directory.')\n",
    "flags.DEFINE_integer('batch_size', 2, help='The batch size.')\n",
    "flags.DEFINE_integer('num_steps', int(2e7), help='Number of steps of training.')\n",
    "flags.DEFINE_float('noise_std', 6.7e-4, help='The std deviation of the noise.')\n",
    "flags.DEFINE_string('model_path', None,\n",
    "                    help=('The path for saving checkpoints of the model. '\n",
    "                          'Defaults to a temporary directory.'))\n",
    "flags.DEFINE_string('output_path', None,\n",
    "                    help='The path for saving outputs (e.g. rollouts).')\n",
    "\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "Stats = collections.namedtuple('Stats', ['mean', 'std'])\n",
    "\n",
    "INPUT_SEQUENCE_LENGTH = 6  # So we can calculate the last 5 velocities.\n",
    "NUM_PARTICLE_TYPES = 9\n",
    "KINEMATIC_PARTICLE_ID = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06dd9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kinematic_mask(particle_types):\n",
    "  \"\"\"Returns a boolean mask, set to true for kinematic (obstacle) particles.\"\"\"\n",
    "  return tf.equal(particle_types, KINEMATIC_PARTICLE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abfbfbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(tensor_dict):\n",
    "  \"\"\"Prepares a single stack of inputs by calculating inputs and targets.\n",
    "\n",
    "  Computes n_particles_per_example, which is a tensor that contains information\n",
    "  about how to partition the axis - i.e. which nodes belong to which graph.\n",
    "\n",
    "  Adds a batch axis to `n_particles_per_example` and `step_context` so they can\n",
    "  later be batched using `batch_concat`. This batch will be the same as if the\n",
    "  elements had been batched via stacking.\n",
    "\n",
    "  Note that all other tensors have a variable size particle axis,\n",
    "  and in this case they will simply be concatenated along that\n",
    "  axis.\n",
    "\n",
    "\n",
    "\n",
    "  Args:\n",
    "    tensor_dict: A dict of tensors containing positions, and step context (\n",
    "    if available).\n",
    "\n",
    "  Returns:\n",
    "    A tuple of input features and target positions.\n",
    "\n",
    "  \"\"\"\n",
    "  # Position is encoded as [sequence_length, num_particles, dim] but the model\n",
    "  # expects [num_particles, sequence_length, dim].\n",
    "  pos = tensor_dict['position']\n",
    "  pos = tf.transpose(pos, perm=[1, 0, 2])\n",
    "\n",
    "  # The target position is the final step of the stack of positions.\n",
    "  target_position = pos[:, -1]\n",
    "\n",
    "  # Remove the target from the input.\n",
    "  tensor_dict['position'] = pos[:, :-1]\n",
    "\n",
    "  # Compute the number of particles per example.\n",
    "  num_particles = tf.shape(pos)[0]\n",
    "  # Add an extra dimension for stacking via concat.\n",
    "  tensor_dict['n_particles_per_example'] = num_particles[tf.newaxis]\n",
    "\n",
    "  if 'step_context' in tensor_dict:\n",
    "    # Take the input global context. We have a stack of global contexts,\n",
    "    # and we take the penultimate since the final is the target.\n",
    "    tensor_dict['step_context'] = tensor_dict['step_context'][-2]\n",
    "    # Add an extra dimension for stacking via concat.\n",
    "    tensor_dict['step_context'] = tensor_dict['step_context'][tf.newaxis]\n",
    "  return tensor_dict, target_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b6593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rollout_inputs(context, features):\n",
    "  \"\"\"Prepares an inputs trajectory for rollout.\"\"\"\n",
    "  out_dict = {**context}\n",
    "  # Position is encoded as [sequence_length, num_particles, dim] but the model\n",
    "  # expects [num_particles, sequence_length, dim].\n",
    "  pos = tf.transpose(features['position'], [1, 0, 2])\n",
    "  # The target position is the final step of the stack of positions.\n",
    "  target_position = pos[:, -1]\n",
    "  # Remove the target from the input.\n",
    "  out_dict['position'] = pos[:, :-1]\n",
    "  # Compute the number of nodes\n",
    "  out_dict['n_particles_per_example'] = [tf.shape(pos)[0]]\n",
    "  if 'step_context' in features:\n",
    "    out_dict['step_context'] = features['step_context']\n",
    "  out_dict['is_trajectory'] = tf.constant([True], tf.bool)\n",
    "  return out_dict, target_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5fe814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_concat(dataset, batch_size):\n",
    "  \"\"\"We implement batching as concatenating on the leading axis.\"\"\"\n",
    "\n",
    "  # We create a dataset of datasets of length batch_size.\n",
    "  windowed_ds = dataset.window(batch_size)\n",
    "\n",
    "  # The plan is then to reduce every nested dataset by concatenating. We can\n",
    "  # do this using tf.data.Dataset.reduce. This requires an initial state, and\n",
    "  # then incrementally reduces by running through the dataset\n",
    "\n",
    "  # Get initial state. In this case this will be empty tensors of the\n",
    "  # correct shape.\n",
    "  initial_state = tree.map_structure(\n",
    "      lambda spec: tf.zeros(  # pylint: disable=g-long-lambda\n",
    "          shape=[0] + spec.shape.as_list()[1:], dtype=spec.dtype),\n",
    "      dataset.element_spec)\n",
    "\n",
    "  # We run through the nest and concatenate each entry with the previous state.\n",
    "  def reduce_window(initial_state, ds):\n",
    "    return ds.reduce(initial_state, lambda x, y: tf.concat([x, y], axis=0))\n",
    "\n",
    "  return windowed_ds.map(\n",
    "      lambda *x: tree.map_structure(reduce_window, initial_state, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1504c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_fn(data_path, batch_size, mode, split):\n",
    "  \"\"\"Gets the learning simulation input function for tf.estimator.Estimator.\n",
    "\n",
    "  Args:\n",
    "    data_path: the path to the dataset directory.\n",
    "    batch_size: the number of graphs in a batch.\n",
    "    mode: either 'one_step_train', 'one_step' or 'rollout'\n",
    "    split: either 'train', 'valid' or 'test.\n",
    "\n",
    "  Returns:\n",
    "    The input function for the learning simulation model.\n",
    "  \"\"\"\n",
    "  def input_fn():\n",
    "    \"\"\"Input function for learning simulation.\"\"\"\n",
    "    # Loads the metadata of the dataset.\n",
    "    metadata = _read_metadata(data_path)\n",
    "    # Create a tf.data.Dataset from the TFRecord.\n",
    "    ds = tf.data.TFRecordDataset([os.path.join(data_path, f'{split}.tfrecord')])\n",
    "    ds = ds.map(functools.partial(\n",
    "        reading_utils.parse_serialized_simulation_example, metadata=metadata))\n",
    "    if mode.startswith('one_step'):\n",
    "      # Splits an entire trajectory into chunks of 7 steps.\n",
    "      # Previous 5 velocities, current velocity and target.\n",
    "      split_with_window = functools.partial(\n",
    "          reading_utils.split_trajectory,\n",
    "          window_length=INPUT_SEQUENCE_LENGTH + 1)\n",
    "      ds = ds.flat_map(split_with_window)\n",
    "      # Splits a chunk into input steps and target steps\n",
    "      ds = ds.map(prepare_inputs)\n",
    "      # If in train mode, repeat dataset forever and shuffle.\n",
    "      if mode == 'one_step_train':\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(512)\n",
    "      # Custom batching on the leading axis.\n",
    "      ds = batch_concat(ds, batch_size)\n",
    "    elif mode == 'rollout':\n",
    "      # Rollout evaluation only available for batch size 1\n",
    "      assert batch_size == 1\n",
    "      ds = ds.map(prepare_rollout_inputs)\n",
    "    else:\n",
    "      raise ValueError(f'mode: {mode} not recognized')\n",
    "    return ds\n",
    "\n",
    "  return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c57d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(simulator, features, num_steps):\n",
    "  \"\"\"Rolls out a trajectory by applying the model in sequence.\"\"\"\n",
    "  initial_positions = features['position'][:, 0:INPUT_SEQUENCE_LENGTH]\n",
    "  ground_truth_positions = features['position'][:, INPUT_SEQUENCE_LENGTH:]\n",
    "  global_context = features.get('step_context')\n",
    "  def step_fn(step, current_positions, predictions):\n",
    "\n",
    "    if global_context is None:\n",
    "      global_context_step = None\n",
    "    else:\n",
    "      global_context_step = global_context[\n",
    "          step + INPUT_SEQUENCE_LENGTH - 1][tf.newaxis]\n",
    "\n",
    "    next_position = simulator(\n",
    "        current_positions,\n",
    "        n_particles_per_example=features['n_particles_per_example'],\n",
    "        particle_types=features['particle_type'],\n",
    "        global_context=global_context_step)\n",
    "\n",
    "    # Update kinematic particles from prescribed trajectory.\n",
    "    kinematic_mask = get_kinematic_mask(features['particle_type'])\n",
    "    next_position_ground_truth = ground_truth_positions[:, step]\n",
    "    next_position = tf.where(kinematic_mask, next_position_ground_truth,\n",
    "                             next_position)\n",
    "    updated_predictions = predictions.write(step, next_position)\n",
    "\n",
    "    # Shift `current_positions`, removing the oldest position in the sequence\n",
    "    # and appending the next position at the end.\n",
    "    next_positions = tf.concat([current_positions[:, 1:],\n",
    "                                next_position[:, tf.newaxis]], axis=1)\n",
    "\n",
    "    return (step + 1, next_positions, updated_predictions)\n",
    "\n",
    "  predictions = tf.TensorArray(size=num_steps, dtype=tf.float32)\n",
    "  _, _, predictions = tf.while_loop(\n",
    "      cond=lambda step, state, prediction: tf.less(step, num_steps),\n",
    "      body=step_fn,\n",
    "      loop_vars=(0, initial_positions, predictions),\n",
    "      back_prop=False,\n",
    "      parallel_iterations=1)\n",
    "\n",
    "  output_dict = {\n",
    "      'initial_positions': tf.transpose(initial_positions, [1, 0, 2]),\n",
    "      'predicted_rollout': predictions.stack(),\n",
    "      'ground_truth_rollout': tf.transpose(ground_truth_positions, [1, 0, 2]),\n",
    "      'particle_types': features['particle_type'],\n",
    "  }\n",
    "\n",
    "  if global_context is not None:\n",
    "    output_dict['global_context'] = global_context\n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bd861ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _combine_std(std_x, std_y):\n",
    "  return np.sqrt(std_x**2 + std_y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f200abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_simulator(model_kwargs, metadata, acc_noise_std, vel_noise_std):\n",
    "  \"\"\"Instantiates the simulator.\"\"\"\n",
    "  # Cast statistics to numpy so they are arrays when entering the model.\n",
    "  cast = lambda v: np.array(v, dtype=np.float32)\n",
    "  acceleration_stats = Stats(\n",
    "      cast(metadata['acc_mean']),\n",
    "      _combine_std(cast(metadata['acc_std']), acc_noise_std))\n",
    "  velocity_stats = Stats(\n",
    "      cast(metadata['vel_mean']),\n",
    "      _combine_std(cast(metadata['vel_std']), vel_noise_std))\n",
    "  normalization_stats = {'acceleration': acceleration_stats,\n",
    "                         'velocity': velocity_stats}\n",
    "  if 'context_mean' in metadata:\n",
    "    context_stats = Stats(\n",
    "        cast(metadata['context_mean']), cast(metadata['context_std']))\n",
    "    normalization_stats['context'] = context_stats\n",
    "\n",
    "  simulator = learned_simulator.LearnedSimulator(\n",
    "      num_dimensions=metadata['dim'],\n",
    "      connectivity_radius=metadata['default_connectivity_radius'],\n",
    "      graph_network_kwargs=model_kwargs,\n",
    "      boundaries=metadata['bounds'],\n",
    "      num_particle_types=NUM_PARTICLE_TYPES,\n",
    "      normalization_stats=normalization_stats,\n",
    "      particle_type_embedding_size=16)\n",
    "  return simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9a805ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_step_estimator_fn(data_path,\n",
    "                              noise_std,\n",
    "                              latent_size=128,\n",
    "                              hidden_size=128,\n",
    "                              hidden_layers=2,\n",
    "                              message_passing_steps=10):\n",
    "  \"\"\"Gets one step model for training simulation.\"\"\"\n",
    "  metadata = _read_metadata(data_path)\n",
    "\n",
    "  model_kwargs = dict(\n",
    "      latent_size=latent_size,\n",
    "      mlp_hidden_size=hidden_size,\n",
    "      mlp_num_hidden_layers=hidden_layers,\n",
    "      num_message_passing_steps=message_passing_steps)\n",
    "\n",
    "  def estimator_fn(features, labels, mode):\n",
    "    target_next_position = labels\n",
    "    simulator = _get_simulator(model_kwargs, metadata,\n",
    "                               vel_noise_std=noise_std,\n",
    "                               acc_noise_std=noise_std)\n",
    "    # Sample the noise to add to the inputs to the model during training.\n",
    "    sampled_noise = noise_utils.get_random_walk_noise_for_position_sequence(\n",
    "        features['position'], noise_std_last_step=noise_std)\n",
    "    non_kinematic_mask = tf.logical_not(\n",
    "        get_kinematic_mask(features['particle_type']))\n",
    "    noise_mask = tf.cast(\n",
    "        non_kinematic_mask, sampled_noise.dtype)[:, tf.newaxis, tf.newaxis]\n",
    "    sampled_noise *= noise_mask\n",
    "\n",
    "    # Get the predictions and target accelerations.\n",
    "    pred_target = simulator.get_predicted_and_target_normalized_accelerations(\n",
    "        next_position=target_next_position,\n",
    "        position_sequence=features['position'],\n",
    "        position_sequence_noise=sampled_noise,\n",
    "        n_particles_per_example=features['n_particles_per_example'],\n",
    "        particle_types=features['particle_type'],\n",
    "        global_context=features.get('step_context'))\n",
    "    pred_acceleration, target_acceleration = pred_target\n",
    "\n",
    "    # Calculate the loss and mask out loss on kinematic particles/\n",
    "    loss = (pred_acceleration - target_acceleration)**2\n",
    "\n",
    "    num_non_kinematic = tf.reduce_sum(\n",
    "        tf.cast(non_kinematic_mask, tf.float32))\n",
    "    loss = tf.where(non_kinematic_mask, loss, tf.zeros_like(loss))\n",
    "    loss = tf.reduce_sum(loss) / tf.reduce_sum(num_non_kinematic)\n",
    "    global_step = tf.train.get_global_step()\n",
    "    # Set learning rate to decay from 1e-4 to 1e-6 exponentially.\n",
    "    min_lr = 1e-6\n",
    "    lr = tf.train.exponential_decay(learning_rate=1e-4 - min_lr,\n",
    "                                    global_step=global_step,\n",
    "                                    decay_steps=int(5e6),\n",
    "                                    decay_rate=0.1) + min_lr\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    train_op = opt.minimize(loss, global_step)\n",
    "\n",
    "    # Calculate next position and add some additional eval metrics (only eval).\n",
    "    predicted_next_position = simulator(\n",
    "        position_sequence=features['position'],\n",
    "        n_particles_per_example=features['n_particles_per_example'],\n",
    "        particle_types=features['particle_type'],\n",
    "        global_context=features.get('step_context'))\n",
    "\n",
    "    predictions = {'predicted_next_position': predicted_next_position}\n",
    "\n",
    "    eval_metrics_ops = {\n",
    "        'loss_mse': tf.metrics.mean_squared_error(\n",
    "            pred_acceleration, target_acceleration),\n",
    "        'one_step_position_mse': tf.metrics.mean_squared_error(\n",
    "            predicted_next_position, target_next_position)\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        train_op=train_op,\n",
    "        loss=loss,\n",
    "        predictions=predictions,\n",
    "        eval_metric_ops=eval_metrics_ops)\n",
    "\n",
    "  return estimator_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bec37e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rollout_estimator_fn(data_path,\n",
    "                             noise_std,\n",
    "                             latent_size=128,\n",
    "                             hidden_size=128,\n",
    "                             hidden_layers=2,\n",
    "                             message_passing_steps=10):\n",
    "  \"\"\"Gets the model function for tf.estimator.Estimator.\"\"\"\n",
    "  metadata = _read_metadata(data_path)\n",
    "\n",
    "  model_kwargs = dict(\n",
    "      latent_size=latent_size,\n",
    "      mlp_hidden_size=hidden_size,\n",
    "      mlp_num_hidden_layers=hidden_layers,\n",
    "      num_message_passing_steps=message_passing_steps)\n",
    "\n",
    "  def estimator_fn(features, labels, mode):\n",
    "    del labels  # Labels to conform to estimator spec.\n",
    "    simulator = _get_simulator(model_kwargs, metadata,\n",
    "                               acc_noise_std=noise_std,\n",
    "                               vel_noise_std=noise_std)\n",
    "\n",
    "    num_steps = metadata['sequence_length'] - INPUT_SEQUENCE_LENGTH\n",
    "    rollout_op = rollout(simulator, features, num_steps=num_steps)\n",
    "    squared_error = (rollout_op['predicted_rollout'] -\n",
    "                     rollout_op['ground_truth_rollout']) ** 2\n",
    "    loss = tf.reduce_mean(squared_error)\n",
    "    eval_ops = {'rollout_error_mse': tf.metrics.mean_squared_error(\n",
    "        rollout_op['predicted_rollout'], rollout_op['ground_truth_rollout'])}\n",
    "\n",
    "    # Add a leading axis, since Estimator's predict method insists that all\n",
    "    # tensors have a shared leading batch axis fo the same dims.\n",
    "    rollout_op = tree.map_structure(lambda x: x[tf.newaxis], rollout_op)\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        train_op=None,\n",
    "        loss=loss,\n",
    "        predictions=rollout_op,\n",
    "        eval_metric_ops=eval_ops)\n",
    "\n",
    "  return estimator_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab12d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_metadata(data_path):\n",
    "  with open(os.path.join(data_path, 'metadata.json'), 'rt') as fp:\n",
    "    return json.loads(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa2bde88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "  \"\"\"Train or evaluates the model.\"\"\"\n",
    "\n",
    "  if FLAGS.mode in ['train', 'eval']:\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        get_one_step_estimator_fn(FLAGS.data_path, FLAGS.noise_std),\n",
    "        model_dir=FLAGS.model_path)\n",
    "    if FLAGS.mode == 'train':\n",
    "      # Train all the way through.\n",
    "      estimator.train(\n",
    "          input_fn=get_input_fn(FLAGS.data_path, FLAGS.batch_size,\n",
    "                                mode='one_step_train', split='train'),\n",
    "          max_steps=FLAGS.num_steps)\n",
    "    else:\n",
    "      # One-step evaluation from checkpoint.\n",
    "      eval_metrics = estimator.evaluate(input_fn=get_input_fn(\n",
    "          FLAGS.data_path, FLAGS.batch_size,\n",
    "          mode='one_step', split=FLAGS.eval_split))\n",
    "      logging.info('Evaluation metrics:')\n",
    "      logging.info(eval_metrics)\n",
    "  elif FLAGS.mode == 'eval_rollout':\n",
    "    if not FLAGS.output_path:\n",
    "      raise ValueError('A rollout path must be provided.')\n",
    "    rollout_estimator = tf.estimator.Estimator(\n",
    "        get_rollout_estimator_fn(FLAGS.data_path, FLAGS.noise_std),\n",
    "        model_dir=FLAGS.model_path)\n",
    "\n",
    "    # Iterate through rollouts saving them one by one.\n",
    "    metadata = _read_metadata(FLAGS.data_path)\n",
    "    rollout_iterator = rollout_estimator.predict(\n",
    "        input_fn=get_input_fn(FLAGS.data_path, batch_size=1,\n",
    "                              mode='rollout', split=FLAGS.eval_split))\n",
    "\n",
    "    for example_index, example_rollout in enumerate(rollout_iterator):\n",
    "      example_rollout['metadata'] = metadata\n",
    "      filename = f'rollout_{FLAGS.eval_split}_{example_index}.pkl'\n",
    "      filename = os.path.join(FLAGS.output_path, filename)\n",
    "      logging.info('Saving: %s.', filename)\n",
    "      if not os.path.exists(FLAGS.output_path):\n",
    "        os.mkdir(FLAGS.output_path)\n",
    "      with open(filename, 'wb') as file:\n",
    "        pickle.dump(example_rollout, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f8bf81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c364ea",
   "metadata": {},
   "source": [
    "## Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0593c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "split='train'\n",
    "data_path = \"./tmp/datasets/Water\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3364cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the metadata of the dataset.\n",
    "metadata = _read_metadata(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32b4f55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': [[0.1, 0.9], [0.1, 0.9]],\n",
       " 'sequence_length': 1000,\n",
       " 'default_connectivity_radius': 0.015,\n",
       " 'dim': 2,\n",
       " 'dt': 0.0025,\n",
       " 'vel_mean': [-4.906372733478189e-06, -0.0003581614249505887],\n",
       " 'vel_std': [0.0018492343327724738, 0.0018154400863548657],\n",
       " 'acc_mean': [-1.3758095862050814e-08, 1.114232425851392e-07],\n",
       " 'acc_std': [0.0001279824304831018, 0.0001388316140032424]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "610c2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tf.data.Dataset from the TFRecord.\n",
    "ds = tf.data.TFRecordDataset([os.path.join(data_path, f'{split}.tfrecord')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a1acfbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function parse_serialized_simulation_example at 0x7f029c2d4670> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Constant'\n",
      "WARNING: Entity <function parse_serialized_simulation_example at 0x7f029c2d4670> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Constant'\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(functools.partial(\n",
    "    reading_utils.parse_serialized_simulation_example, metadata=metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "67ce06a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(prepare_rollout_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b833a032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ({particle_type: (?,), key: (), position: (?, 1000, 2), n_particles_per_example: (1,), is_trajectory: (1,)}, (?, 2)), types: ({particle_type: tf.int64, key: tf.int64, position: tf.float32, n_particles_per_example: tf.int32, is_trajectory: tf.bool}, tf.float32)>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "26e4dcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'particle_type': TensorSpec(shape=(?,), dtype=tf.int64, name=None),\n",
       "  'key': TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
       "  'position': TensorSpec(shape=(?, 1000, 2), dtype=tf.float32, name=None),\n",
       "  'n_particles_per_example': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       "  'is_trajectory': TensorSpec(shape=(1,), dtype=tf.bool, name=None)},\n",
       " TensorSpec(shape=(?, 2), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b58cc48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ({particle_type: (?,), key: (), position: (?, 1000, 2), n_particles_per_example: (1,), is_trajectory: (1,)}, (?, 2)), types: ({particle_type: tf.int64, key: tf.int64, position: tf.float32, n_particles_per_example: tf.int32, is_trajectory: tf.bool}, tf.float32)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "93b07030",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_iterator = tf.python_io.tf_record_iterator(path=os.path.join(data_path, f'{split}.tfrecord'))\n",
    "for string_record in record_iterator:\n",
    "    example = tf.train.Example()\n",
    "#     record = reading_utils.parse_serialized_simulation_example(string_record, metadata=metadata)\n",
    "    example.ParseFromString(string_record)\n",
    "#     print(example)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "360e59e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.core.example.example_pb2.Example"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "600d0c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1718497"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.ByteSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "38bf0922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"key\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"particle_type\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e6e9c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5e1c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = dict(\n",
    "  latent_size=128,\n",
    "  mlp_hidden_size=128,\n",
    "  mlp_num_hidden_layers=2,\n",
    "  num_message_passing_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5111392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_std = 6.7e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "644c5c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = _get_simulator(model_kwargs, metadata,\n",
    "                           vel_noise_std=noise_std,\n",
    "                           acc_noise_std=noise_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "532a6ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<learning_to_simulate.learned_simulator.LearnedSimulator at 0x7f029be870d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf56e354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<learning_to_simulate.graph_network.EncodeProcessDecode at 0x7f029b61c760>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator._graph_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a00b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
