{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14d61a74",
   "metadata": {},
   "source": [
    "# Sonnet + tf1 + tensorboard tutorial\n",
    "https://qiita.com/n-suzuki/items/f6cb8bf5efff0f82d44d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "445b4317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 03:04:03.808414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow will not use sklearn by default. This improves performance in some cases. To enable sklearn export the environment variable  TF_ALLOW_IOLIBS=1.\n",
      "WARNING:tensorflow:TensorFlow will not use Dask by default. This improves performance in some cases. To enable Dask export the environment variable  TF_ALLOW_IOLIBS=1.\n",
      "WARNING:tensorflow:TensorFlow will not use Pandas by default. This improves performance in some cases. To enable Pandas export the environment variable  TF_ALLOW_IOLIBS=1.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sonnet as snt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed27d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # モデル定義\n",
    "# class MLP(snt.AbstractModule):\n",
    "#     def __init__(self, output_size, nonlinearity=tf.nn.relu, name='mlp'):\n",
    "#         super(MLP, self).__init__(name=name)\n",
    "#         self._output_size = output_size\n",
    "#         self._nonlinearity = nonlinearity\n",
    "\n",
    "#     # 順伝播を記述\n",
    "#     def _build(self, inputs, is_training):\n",
    "#         conv1 = snt.Conv2D(output_channels=16, kernel_shape=3, stride=1, name='conv1')\n",
    "#         h = self._nonlinearity(conv1(inputs))\n",
    "#         h = snt.BatchNorm(name='bn1')(h, is_training=is_training)\n",
    "\n",
    "#         conv2 = snt.Conv2D(output_channels=16, kernel_shape=3, stride=1, name='conv2')\n",
    "#         h = self._nonlinearity(conv2(h))\n",
    "#         h = snt.BatchNorm(name='bn2')(h, is_training=is_training)\n",
    "#         h = snt.BatchFlatten(name='bf')(h)\n",
    "\n",
    "#         l = snt.Linear(output_size=self._output_size, name='l')\n",
    "#         outputs = tf.nn.softmax(l(h))\n",
    "\n",
    "#         return outputs\n",
    "\n",
    "# モデル定義\n",
    "class MLP(snt.AbstractModule):\n",
    "    def __init__(self, output_size, nonlinearity=tf.nn.relu, name='mlp'):\n",
    "        super(MLP, self).__init__(name=name)\n",
    "        self._output_size = output_size\n",
    "        self._nonlinearity = nonlinearity\n",
    "\n",
    "        # 学習パラメータ設定（_build()の内部で書くことも可）\n",
    "        with self._enter_variable_scope():\n",
    "            self._conv1 = snt.Conv2D(output_channels=16, kernel_shape=3, stride=1, name='conv1')\n",
    "            self._bn1 = snt.BatchNorm(name='bn1')\n",
    "            self._conv2 = snt.Conv2D(output_channels=16, kernel_shape=3, stride=1, name='conv2')\n",
    "            self._bn2 = snt.BatchNorm(name='bn2')\n",
    "            self._bf = snt.BatchFlatten(name='bf')\n",
    "            self._l = snt.Linear(output_size=self._output_size, name='l')\n",
    "\n",
    "    # 順伝播を記述（Chainerで言うところのforward(), __call__()）\n",
    "    def _build(self, inputs, is_training):\n",
    "        cnv1 = self._conv1\n",
    "        h = self._nonlinearity(cnv1(inputs))\n",
    "        h = self._bn1(h, is_training=is_training)\n",
    "\n",
    "        cnv2 = self._conv2\n",
    "        h = self._nonlinearity(cnv2(h))\n",
    "        h = self._bn2(h, is_training=is_training)\n",
    "        h = self._bf(h)\n",
    "\n",
    "        l = self._l\n",
    "        outputs = tf.nn.softmax(l(h))\n",
    "\n",
    "        return outputs, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab2123fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# MNISTデータセット\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "\n",
    "# データセットのインスタンス（class MNISTに mnist.train, mnist.validation, mnist.testをそれぞれ渡す）\n",
    "mnist = read_data_sets('./MNIST_data', one_hot=True)\n",
    "\n",
    "# データセットモジュール定義\n",
    "class MNIST(snt.AbstractModule):\n",
    "    def __init__(self, mnist, batch_size, name='mnist'):\n",
    "        super(MNIST, self).__init__(name=name)\n",
    "\n",
    "        # データ数\n",
    "        self._num_examples = mnist.num_examples\n",
    "        # 画像(tf.constant)\n",
    "        self._images = tf.constant(mnist.images, dtype=tf.float32)\n",
    "        # ラベル(tf.constant)\n",
    "        self._labels = tf.constant(mnist.labels, dtype=tf.float32)\n",
    "        self._batch_size = batch_size\n",
    "\n",
    "    def _build(self):\n",
    "        # サンプラー(バッチ数)\n",
    "        indices = tf.random_uniform([self._batch_size], 0, self._num_examples, tf.int64)\n",
    "        x = tf.reshape(tf.gather(self._images, indices), (self._batch_size, 1, 28, 28))\n",
    "        y_ = tf.gather(self._labels, indices)\n",
    "        return x, y_\n",
    "\n",
    "    def cost(self, logits, target):\n",
    "        loss = -tf.reduce_sum(target * tf.log(logits))\n",
    "        return loss\n",
    "\n",
    "    def evaluation(self, logits, target):\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(target, 1))\n",
    "        acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6587f10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x7fe97fbeb250>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6ac2b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_104/3573286557.py:22: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_104/3573286557.py:28: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_104/1057945661.py:27: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_104/1057945661.py:53: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# パラメータ設定\n",
    "# TensorFlowと同じ\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "\n",
    "tf.flags.DEFINE_integer(\"num_training_iterations\", 2000, \"Number of iterations to train for.\")\n",
    "tf.flags.DEFINE_integer(\"report_interval\", 50, \"Iterations between reports (samples, valid loss).\")\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 64, \"Batch size for training.\")\n",
    "tf.flags.DEFINE_integer(\"output_size\", 10, \"Size of MLP output layer.\")\n",
    "\n",
    "# データ供給用オブジェクトを作成\n",
    "dataset_train = MNIST(mnist.train, batch_size=FLAGS.batch_size, name='mnist_train')\n",
    "dataset_validation = MNIST(mnist.validation, batch_size=FLAGS.batch_size, name='mnist_validation')\n",
    "dataset_test = MNIST(mnist.test, batch_size=FLAGS.batch_size, name='mnist_test')\n",
    "\n",
    "# make MLP object\n",
    "model = MLP(output_size=FLAGS.output_size, nonlinearity=tf.nn.relu)\n",
    "\n",
    "# Build the training model and get the training loss.\n",
    "# データ抽出\n",
    "train_x, train_y_ = dataset_train()\n",
    "# モデル順伝播\n",
    "train_y, _ = model(train_x, True)\n",
    "# loss計算\n",
    "train_loss = dataset_train.cost(train_y, train_y_)\n",
    "# lossをsummaryに保存（TensorBoard用）\n",
    "tf.summary.scalar('loss', train_loss)\n",
    "\n",
    "# Get the validation loss.\n",
    "# データ抽出\n",
    "validation_x, validation_y_ = dataset_validation()\n",
    "# モデル順伝播\n",
    "validation_y, _ = model(validation_x, False)\n",
    "# loss計算\n",
    "validation_loss = dataset_validation.evaluation(validation_y, validation_y_)\n",
    "# validation accuracyをsummaryに保存（TensorBoard用）\n",
    "tf.summary.scalar('validation_accuracy', validation_loss)\n",
    "\n",
    "# Get the test loss.\n",
    "# データ抽出\n",
    "test_x, test_y_ = dataset_test()\n",
    "# モデル順伝播\n",
    "test_y, _ = model(test_x, False)\n",
    "# loss計算\n",
    "test_loss = dataset_test.evaluation(test_y, test_y_)\n",
    "# test accuracyをsummaryに保存（TensorBoard用）\n",
    "tf.summary.scalar('test_accuracy', test_loss)\n",
    "\n",
    "# 中間層出力を取得(TensorBoard用)\n",
    "_, features = model(tf.reshape(tf.constant(mnist.test.images, dtype=tf.float32), (-1, 1, 28, 28)), False)\n",
    "\n",
    "# Set up optimizer.\n",
    "train_step = tf.train.AdamOptimizer().minimize(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "459ff21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17294afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_104/3256654321.py:2: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_104/3256654321.py:2: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_104/3256654321.py:7: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 03:04:07.395414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-03 03:04:07.442978: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:07.443029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: NVIDIA RTX A4000 major: 8 minor: 6 memoryClockRate(GHz): 1.56\n",
      "pciBusID: 0000:15:00.0\n",
      "2022-04-03 03:04:07.443548: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:21:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:07.443596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 1 with properties: \n",
      "name: Quadro P2000 major: 6 minor: 1 memoryClockRate(GHz): 1.4805\n",
      "pciBusID: 0000:21:00.0\n",
      "2022-04-03 03:04:07.443649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-04-03 03:04:07.449998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-04-03 03:04:07.499757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-03 03:04:07.500400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-03 03:04:07.501323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-04-03 03:04:07.503662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-04-03 03:04:07.503869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-04-03 03:04:07.504339: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:07.504677: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:21:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:07.504928: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:07.505173: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:21:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:07.505192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0, 1\n",
      "2022-04-03 03:04:07.518003: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3599995000 Hz\n",
      "2022-04-03 03:04:07.518768: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x65e63b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-03 03:04:07.518819: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-04-03 03:04:07.806753: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:07.853294: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:21:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:07.853587: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6043180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-03 03:04:07.853611: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A4000, Compute Capability 8.6\n",
      "2022-04-03 03:04:07.853617: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Quadro P2000, Compute Capability 6.1\n",
      "2022-04-03 03:04:07.854321: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:07.854375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: NVIDIA RTX A4000 major: 8 minor: 6 memoryClockRate(GHz): 1.56\n",
      "pciBusID: 0000:15:00.0\n",
      "2022-04-03 03:04:07.854834: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:21:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:07.854898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 1 with properties: \n",
      "name: Quadro P2000 major: 6 minor: 1 memoryClockRate(GHz): 1.4805\n",
      "pciBusID: 0000:21:00.0\n",
      "2022-04-03 03:04:07.854952: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-04-03 03:04:07.855003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-04-03 03:04:07.855025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-03 03:04:07.855039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-03 03:04:07.855053: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-04-03 03:04:07.855066: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-04-03 03:04:07.855079: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-04-03 03:04:07.855641: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:07.856237: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:21:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:07.856824: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:07.857539: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:21:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:07.857595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0, 1\n",
      "2022-04-03 03:04:07.857700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_104/3256654321.py:9: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 03:04:08.949469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-03 03:04:08.949599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 1 \n",
      "2022-04-03 03:04:08.949622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N N \n",
      "2022-04-03 03:04:08.949633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 1:   N N \n",
      "2022-04-03 03:04:08.951040: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:08.951206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-04-03 03:04:08.952089: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:21:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:08.952241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Could not identify NUMA node of platform GPU id 1, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-04-03 03:04:08.953097: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:15:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:08.953300: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-04-03 03:04:08.953368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13346 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:15:00.0, compute capability: 8.6)\n",
      "2022-04-03 03:04:08.954458: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1068] could not open file to read NUMA node: /sys/bus/pci/devices/0000:21:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-03 03:04:08.954533: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-04-03 03:04:08.954568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 3446 MB memory) -> physical GPU (device: 1, name: Quadro P2000, pci bus id: 0000:21:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_104/3256654321.py:10: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_104/3256654321.py:11: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 03:04:12.787630: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-04-03 03:04:13.967354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_104/3256654321.py:20: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:50: Training loss 44.182106. Validation accuracy 0.875000.\n",
      "INFO:tensorflow:100: Training loss 24.493500. Validation accuracy 0.890625.\n",
      "INFO:tensorflow:150: Training loss 12.921508. Validation accuracy 0.843750.\n",
      "INFO:tensorflow:200: Training loss 22.235863. Validation accuracy 0.937500.\n",
      "INFO:tensorflow:250: Training loss 7.079167. Validation accuracy 0.984375.\n",
      "INFO:tensorflow:300: Training loss 11.622228. Validation accuracy 0.921875.\n",
      "INFO:tensorflow:350: Training loss 11.841982. Validation accuracy 0.968750.\n",
      "INFO:tensorflow:400: Training loss 6.350767. Validation accuracy 0.968750.\n",
      "INFO:tensorflow:450: Training loss 9.863495. Validation accuracy 0.968750.\n",
      "INFO:tensorflow:500: Training loss 16.098486. Validation accuracy 0.953125.\n",
      "INFO:tensorflow:550: Training loss 7.133687. Validation accuracy 0.968750.\n",
      "INFO:tensorflow:600: Training loss 11.677952. Validation accuracy 0.953125.\n",
      "INFO:tensorflow:650: Training loss 15.746884. Validation accuracy 0.968750.\n",
      "INFO:tensorflow:700: Training loss 9.648560. Validation accuracy 0.984375.\n",
      "INFO:tensorflow:750: Training loss 3.833544. Validation accuracy 1.000000.\n",
      "INFO:tensorflow:800: Training loss 11.734239. Validation accuracy 0.984375.\n",
      "INFO:tensorflow:850: Training loss 5.323456. Validation accuracy 0.953125.\n",
      "INFO:tensorflow:900: Training loss 10.007802. Validation accuracy 0.937500.\n",
      "INFO:tensorflow:950: Training loss 10.029372. Validation accuracy 0.906250.\n",
      "INFO:tensorflow:1000: Training loss 8.681424. Validation accuracy 0.984375.\n",
      "INFO:tensorflow:1050: Training loss 4.106044. Validation accuracy 0.953125.\n",
      "INFO:tensorflow:1100: Training loss 6.314940. Validation accuracy 0.984375.\n",
      "INFO:tensorflow:1150: Training loss 5.588084. Validation accuracy 0.984375.\n",
      "INFO:tensorflow:1200: Training loss 3.143621. Validation accuracy 0.968750.\n",
      "INFO:tensorflow:1250: Training loss 6.969521. Validation accuracy 1.000000.\n",
      "INFO:tensorflow:1300: Training loss 8.920441. Validation accuracy 0.968750.\n",
      "INFO:tensorflow:1350: Training loss 4.021640. Validation accuracy 0.937500.\n",
      "INFO:tensorflow:1400: Training loss 7.823402. Validation accuracy 0.937500.\n",
      "INFO:tensorflow:1450: Training loss 10.717840. Validation accuracy 0.953125.\n",
      "INFO:tensorflow:1500: Training loss 1.172340. Validation accuracy 1.000000.\n",
      "INFO:tensorflow:1550: Training loss 5.857846. Validation accuracy 0.968750.\n",
      "INFO:tensorflow:1600: Training loss 4.988509. Validation accuracy 0.968750.\n",
      "INFO:tensorflow:1650: Training loss 9.445074. Validation accuracy 0.984375.\n",
      "INFO:tensorflow:1700: Training loss 4.566223. Validation accuracy 0.953125.\n",
      "INFO:tensorflow:1750: Training loss 4.355936. Validation accuracy 0.968750.\n",
      "INFO:tensorflow:1800: Training loss 2.933738. Validation accuracy 0.984375.\n",
      "INFO:tensorflow:1850: Training loss 5.409346. Validation accuracy 0.953125.\n",
      "INFO:tensorflow:1900: Training loss 1.934925. Validation accuracy 0.953125.\n",
      "INFO:tensorflow:1950: Training loss 9.260973. Validation accuracy 0.953125.\n",
      "INFO:tensorflow:2000: Training loss 2.502131. Validation accuracy 0.953125.\n",
      "INFO:tensorflow:Test accuracy 1.000000.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_104/3256654321.py:31: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_104/3256654321.py:34: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loggingレベルの設定\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# training \n",
    "# モデル保存先ディレクトリ（=TensorBoardの--logdir）\n",
    "log_dir = 'test_sonnet/'\n",
    "with tf.Session() as sess:\n",
    "    # パラメータ初期化\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "\n",
    "    # メインループ\n",
    "    for training_iteration in range(1, FLAGS.num_training_iterations + 1):\n",
    "        # with validation\n",
    "        if (training_iteration) % FLAGS.report_interval == 0:\n",
    "            # train, validationのloss計算、optimize\n",
    "            summary_, train_loss_v, validation_loss_v, _ = sess.run((merged, train_loss, validation_loss, train_step))\n",
    "            # logging\n",
    "            tf.logging.info(\"%d: Training loss %f. Validation accuracy %f.\", training_iteration, train_loss_v, validation_loss_v)\n",
    "            writer.add_summary(summary_, training_iteration)\n",
    "        else:\n",
    "            summary_, train_loss_v, _ = sess.run((merged, train_loss, train_step))\n",
    "            writer.add_summary(summary_, training_iteration)\n",
    "    test_loss_v = sess.run(test_loss)\n",
    "    tf.logging.info(\"Test accuracy %f.\", test_loss_v)\n",
    "\n",
    "    # 中間層出力を取得してembedding_varとして保存\n",
    "    feature = sess.run(features)\n",
    "    embedding_var = tf.Variable(tf.stack([tf.squeeze(x) for x in feature], axis=0), trainable=False, name='feature')\n",
    "    sess.run(tf.variables_initializer([embedding_var]))\n",
    "\n",
    "    # モデルを保存\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, log_dir + \"model.ckpt\")\n",
    "\n",
    "    # TensorBoardの設定（PROJECTOR用）\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = embedding_var.name\n",
    "    # メタデータのファイル名\n",
    "    embedding.metadata_path = 'labels.tsv'\n",
    "    # sprite画像のファイル名\n",
    "    embedding.sprite.image_path = 'mnist_10k_sprite.png'\n",
    "    # sprite画像の画像サイズ\n",
    "    embedding.sprite.single_image_dim.extend([28, 28])\n",
    "\n",
    "    projector.visualize_embeddings(writer, config)\n",
    "\n",
    "# label to TSV \n",
    "import numpy as np\n",
    "ls = np.argmax(mnist.test.labels, axis=1)\n",
    "\n",
    "with open(log_dir + 'labels.tsv', 'w') as f:\n",
    "    f.write('number\\tlabel\\n')\n",
    "    for i, l in enumerate(ls):\n",
    "        f.write('{}\\t{}\\n'.format(i, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d393561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "542b12fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cgi' has no attribute 'escape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtensorboard\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--logdir test_sonnet/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:2204\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2202\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2204\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorboard/notebook.py:120\u001b[0m, in \u001b[0;36m_start_magic\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_start_magic\u001b[39m(line):\n\u001b[1;32m    119\u001b[0m   \u001b[38;5;124;03m\"\"\"Implementation of the `%tensorboard` line magic.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorboard/notebook.py:158\u001b[0m, in \u001b[0;36mstart\u001b[0;34m(args_string)\u001b[0m\n\u001b[1;32m    155\u001b[0m start_result \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mstart(parsed_args)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(start_result, manager\u001b[38;5;241m.\u001b[39mStartLaunched):\n\u001b[0;32m--> 158\u001b[0m   \u001b[43m_display\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m      \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m      \u001b[49m\u001b[43mprint_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdisplay_handle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(start_result, manager\u001b[38;5;241m.\u001b[39mStartReused):\n\u001b[1;32m    165\u001b[0m   template \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    166\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReusing TensorBoard on port \u001b[39m\u001b[38;5;132;01m{port}\u001b[39;00m\u001b[38;5;124m (pid \u001b[39m\u001b[38;5;132;01m{pid}\u001b[39;00m\u001b[38;5;124m), started \u001b[39m\u001b[38;5;132;01m{delta}\u001b[39;00m\u001b[38;5;124m ago. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m!kill \u001b[39m\u001b[38;5;132;01m{pid}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to kill it.)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorboard/notebook.py:316\u001b[0m, in \u001b[0;36m_display\u001b[0;34m(port, height, print_message, display_handle)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    311\u001b[0m fn \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    312\u001b[0m     _CONTEXT_COLAB: _display_colab,\n\u001b[1;32m    313\u001b[0m     _CONTEXT_IPYTHON: _display_ipython,\n\u001b[1;32m    314\u001b[0m     _CONTEXT_NONE: _display_cli,\n\u001b[1;32m    315\u001b[0m }[_get_context()]\n\u001b[0;32m--> 316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_handle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_handle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorboard/notebook.py:416\u001b[0m, in \u001b[0;36m_display_ipython\u001b[0;34m(port, height, display_handle)\u001b[0m\n\u001b[1;32m    402\u001b[0m frame_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard-frame-\u001b[39m\u001b[38;5;132;01m{:08x}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(random\u001b[38;5;241m.\u001b[39mgetrandbits(\u001b[38;5;241m64\u001b[39m))\n\u001b[1;32m    403\u001b[0m shell \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124m    <iframe id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mHTML_ID\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m height=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mHEIGHT\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m frameborder=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;124m    </iframe>\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124m    </script>\u001b[39m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    415\u001b[0m replacements \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 416\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mHTML_ID\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mcgi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mescape\u001b[49m(frame_id, quote\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)),\n\u001b[1;32m    417\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mJSON_ID\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(frame_id)),\n\u001b[1;32m    418\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mPORT\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m port),\n\u001b[1;32m    419\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mHEIGHT\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m height),\n\u001b[1;32m    420\u001b[0m ]\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (k, v) \u001b[38;5;129;01min\u001b[39;00m replacements:\n\u001b[1;32m    422\u001b[0m   shell \u001b[38;5;241m=\u001b[39m shell\u001b[38;5;241m.\u001b[39mreplace(k, v)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cgi' has no attribute 'escape'"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir test_sonnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9166d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
